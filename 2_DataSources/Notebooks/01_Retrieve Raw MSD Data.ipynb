{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import boto3\n",
    "import tables\n",
    "import sqlite3\n",
    "from s3fs.core import S3FileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 4.8.2\r\n"
     ]
    }
   ],
   "source": [
    "!conda --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Million Song Metadata Ingest\n",
    "\n",
    "Welcome! This notebook is Step 1 in creating the backbone that underlies lucyd. This is functional one-shot code, so please forgive the lack of modularity. \n",
    "\n",
    "This notebook is run on an AWS EC2 instance with:\n",
    "    + Python 3.7.6\n",
    "    + conda 4.8.2\n",
    "    + EC2 size = t3.xlarge\n",
    "    + OS = Amazon Linux AMI, release 2018.03\n",
    "\n",
    "\n",
    "We'll walk you through the steps we took carefully below, but, in general, the steps are as follows:\n",
    "\n",
    "    1) Download the data from http://millionsongdataset.com/sites/default/files/AdditionalFiles/msd_summary_file.h5\n",
    "    2) Download artist level tag database from http://www.ee.columbia.edu/~thierry/artist_term.db\n",
    "    3) Retrieve all relevant fields from the data\n",
    "    4) Crosswalk with Spotify URIs\n",
    "    5) Export to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['songs']>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this .h5 file was retrieved from the link above using this simple command on the EC2 instance:\n",
    "## wget http://millionsongdataset.com/sites/default/files/AdditionalFiles/msd_summary_file.h5\n",
    "f = h5py.File('./msd_summary_file.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Artist-Level Tags to Merge on Later\n",
    "\n",
    "Using the database we describe below, we're going to make a little dataframe mapping Arist ID to some curated artist level tags. Later, we'll merge these onto the million song metadata by artist_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>all_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR002UA1187B9A637D</td>\n",
       "      <td>garage rock,country rock,free jazz,oi,space ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR003FB1187B994355</td>\n",
       "      <td>rock,punk,alternative rock,hip hop,texas,unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR006821187FB5192B</td>\n",
       "      <td>orchestra,opera,religious music,requiem,califo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR009211187B989185</td>\n",
       "      <td>lovers rock,reggae,roots reggae,uk garage,ball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR009SZ1187B9A73F4</td>\n",
       "      <td>chill-out,future jazz,neofolk,downtempo,folktr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id                                          all_terms\n",
       "0  AR002UA1187B9A637D  garage rock,country rock,free jazz,oi,space ro...\n",
       "1  AR003FB1187B994355  rock,punk,alternative rock,hip hop,texas,unite...\n",
       "2  AR006821187FB5192B  orchestra,opera,religious music,requiem,califo...\n",
       "3  AR009211187B989185  lovers rock,reggae,roots reggae,uk garage,ball...\n",
       "4  AR009SZ1187B9A73F4  chill-out,future jazz,neofolk,downtempo,folktr..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this .db file was retrieved from the link above using this simple command on the EC2 instance:\n",
    "## wget http://www.ee.columbia.edu/~thierry/artist_term.db\n",
    "con = sqlite3.connect(\"./artist_term.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "#query for all MusicBrainz artist-level tags \n",
    "##then, make a DF out of it\n",
    "cur.execute(\"select * from artist_mbtag;\")\n",
    "artist_mbtags = cur.fetchall()\n",
    "artist_mbtags = pd.DataFrame(artist_mbtags, columns = ['artist_id','artist_mbtags'])\n",
    "#the data is unique by artist/tag, so roll it up to exist on a single line delim by comma\n",
    "artist_mbtags = artist_mbtags.groupby('artist_id')['artist_mbtags'] \\\n",
    "                             .apply(lambda x: ','.join(x)).reset_index().drop_duplicates('artist_mbtags')\n",
    "\n",
    "#query for all EchoNext artist-level tags\n",
    "##then, make a DF out of it\n",
    "cur.execute(\"select * from artist_term;\")\n",
    "artist_terms = cur.fetchall()\n",
    "artist_terms = pd.DataFrame(artist_terms, columns = ['artist_id','artist_terms'])\n",
    "#the data is unique by artist/tag, so roll it up to exist on a single line delim by comma\n",
    "artist_terms = artist_terms.groupby('artist_id')['artist_terms'] \\\n",
    "                           .apply(lambda x: ','.join(x)).reset_index().drop_duplicates('artist_id')\n",
    "\n",
    "#close that connection!\n",
    "con.close()\n",
    "\n",
    "#slap these two puppies together\n",
    "terms = pd.merge(artist_terms,artist_mbtags,on = 'artist_id', how = 'outer')\n",
    "#make both resulting fields the missing string instead of np.NaN\n",
    "terms['artist_terms'] = np.where(terms['artist_terms'].isnull(),\"\",terms['artist_terms'])\n",
    "terms['artist_mbtags'] = np.where(terms['artist_mbtags'].isnull(),\"\",terms['artist_mbtags'])\n",
    "\n",
    "#make a new field that's just the concat of those strings\n",
    "terms['all_terms'] = terms['artist_terms'] + terms['artist_mbtags']\n",
    "terms = terms.loc[:,['artist_id','all_terms']]\n",
    "terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Million Song Metadata\n",
    "\n",
    "We don't need alllll of the data from the Million Song Dataset. Our platform, lucyd, is all about getting the songs you want to hear using only the tags generated by users! Therefore, we're going to intentionally avoid using acoustic characteristics. As a result, we only need some high level information for each song.\n",
    "\n",
    "For more information about each field, see the field list here: http://millionsongdataset.com/faq/#field-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reach in each one and then concat at the end\n",
    "song_id = pd.Series(f['metadata']['songs']['song_id'])\n",
    "track_id = pd.Series(f['analysis']['songs']['track_id'])\n",
    "hotness = pd.Series(f['metadata']['songs']['song_hotttnesss'])\n",
    "familiar = pd.Series(f['metadata']['songs']['artist_familiarity'])\n",
    "digital7 = pd.Series(f['metadata']['songs']['track_7digitalid'])\n",
    "title = pd.Series(f['metadata']['songs']['title'])\n",
    "artist = pd.Series(f['metadata']['songs']['artist_name'])\n",
    "artist_id = pd.DataFrame(f['metadata']['songs']['artist_id'])\n",
    "mode = pd.Series(f['analysis']['songs']['mode'])\n",
    "key = pd.Series(f['analysis']['songs']['key'])\n",
    "tempo = pd.Series(f['analysis']['songs']['tempo'])\n",
    "\n",
    "flat_summary = pd.concat([song_id,track_id,hotness,familiar,digital7,title,artist,artist_id,mode,tempo,key], axis = 1)\n",
    "flat_summary.columns = ['song_id','track_id','song_hotness','artist_familiarity','7digital_id','title','artist','artist_id','mode','tempo','key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Cleaning and Crosswalking\n",
    "\n",
    "All strings are stored as bytestrings. So, we'll decode them to be proper utf-8 encoded. \n",
    "\n",
    "After, we'll start crosswalking to pull in the artist level terms and the Spotify URIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming: song_id\n",
      "Transforming: track_id\n",
      "Transforming: title\n",
      "Transforming: artist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_hotness</th>\n",
       "      <th>artist_familiarity</th>\n",
       "      <th>7digital_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>mode</th>\n",
       "      <th>tempo</th>\n",
       "      <th>key</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td>TRMMMYQ128F932D901</td>\n",
       "      <td>0.542899</td>\n",
       "      <td>0.649822</td>\n",
       "      <td>7032331</td>\n",
       "      <td>Silent Night</td>\n",
       "      <td>Faster Pussy cat</td>\n",
       "      <td>0</td>\n",
       "      <td>87.002</td>\n",
       "      <td>10</td>\n",
       "      <td>ARYZTJS1187B98C555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOVFVAK12A8C1350D9</td>\n",
       "      <td>TRMMMKD128F425225D</td>\n",
       "      <td>0.299877</td>\n",
       "      <td>0.439604</td>\n",
       "      <td>1514808</td>\n",
       "      <td>Tanssi vaan</td>\n",
       "      <td>Karkkiautomaatti</td>\n",
       "      <td>1</td>\n",
       "      <td>150.778</td>\n",
       "      <td>9</td>\n",
       "      <td>ARMVN3U1187FB3A1EB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOGTUKN12AB017F4F1</td>\n",
       "      <td>TRMMMRX128F93187D9</td>\n",
       "      <td>0.617871</td>\n",
       "      <td>0.643681</td>\n",
       "      <td>6945353</td>\n",
       "      <td>No One Could Ever</td>\n",
       "      <td>Hudson Mohawke</td>\n",
       "      <td>1</td>\n",
       "      <td>177.768</td>\n",
       "      <td>7</td>\n",
       "      <td>ARGEKB01187FB50750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOBNYVR12A8C13558C</td>\n",
       "      <td>TRMMMCH128F425532C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.448501</td>\n",
       "      <td>2168257</td>\n",
       "      <td>Si Vos Querés</td>\n",
       "      <td>Yerba Brava</td>\n",
       "      <td>1</td>\n",
       "      <td>87.433</td>\n",
       "      <td>7</td>\n",
       "      <td>ARNWYLR1187B9B2F9C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOHSBXH12A8C13B0DF</td>\n",
       "      <td>TRMMMWA128F426B589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2264873</td>\n",
       "      <td>Tangle Of Aspens</td>\n",
       "      <td>Der Mystic</td>\n",
       "      <td>0</td>\n",
       "      <td>140.035</td>\n",
       "      <td>5</td>\n",
       "      <td>AREQDTE1269FB37231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>SOTXAME12AB018F136</td>\n",
       "      <td>TRYYYUS12903CD2DF0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528617</td>\n",
       "      <td>7522478</td>\n",
       "      <td>O Samba Da Vida</td>\n",
       "      <td>Kiko Navarro</td>\n",
       "      <td>0</td>\n",
       "      <td>92.159</td>\n",
       "      <td>7</td>\n",
       "      <td>AR7Z4J81187FB3FC59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>SOXQYIQ12A8C137FBB</td>\n",
       "      <td>TRYYYJO128F426DA37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>1632096</td>\n",
       "      <td>Jago Chhadeo</td>\n",
       "      <td>Kuldeep Manak</td>\n",
       "      <td>1</td>\n",
       "      <td>156.132</td>\n",
       "      <td>5</td>\n",
       "      <td>ART5FZD1187B9A7FCF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>SOHODZI12A8C137BB3</td>\n",
       "      <td>TRYYYMG128F4260ECA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556918</td>\n",
       "      <td>2219291</td>\n",
       "      <td>Novemba</td>\n",
       "      <td>Gabriel Le Mar</td>\n",
       "      <td>0</td>\n",
       "      <td>137.089</td>\n",
       "      <td>11</td>\n",
       "      <td>ARZ3R6M1187B9AF750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>SOLXGOR12A81C21EB7</td>\n",
       "      <td>TRYYYDJ128F9310A21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403668</td>\n",
       "      <td>5472456</td>\n",
       "      <td>Faraday</td>\n",
       "      <td>Elude</td>\n",
       "      <td>0</td>\n",
       "      <td>137.928</td>\n",
       "      <td>6</td>\n",
       "      <td>ARCMCOK1187B9B1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>SOWXJXQ12AB0189F43</td>\n",
       "      <td>TRYYYVU12903CD01E3</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.552977</td>\n",
       "      <td>8486723</td>\n",
       "      <td>Fernweh feat. Sektion Kuchikäschtli</td>\n",
       "      <td>Texta</td>\n",
       "      <td>1</td>\n",
       "      <td>164.037</td>\n",
       "      <td>6</td>\n",
       "      <td>AR7PLM21187B990D08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song_id            track_id  song_hotness  \\\n",
       "0       SOQMMHC12AB0180CB8  TRMMMYQ128F932D901      0.542899   \n",
       "1       SOVFVAK12A8C1350D9  TRMMMKD128F425225D      0.299877   \n",
       "2       SOGTUKN12AB017F4F1  TRMMMRX128F93187D9      0.617871   \n",
       "3       SOBNYVR12A8C13558C  TRMMMCH128F425532C           NaN   \n",
       "4       SOHSBXH12A8C13B0DF  TRMMMWA128F426B589           NaN   \n",
       "...                    ...                 ...           ...   \n",
       "999995  SOTXAME12AB018F136  TRYYYUS12903CD2DF0           NaN   \n",
       "999996  SOXQYIQ12A8C137FBB  TRYYYJO128F426DA37           NaN   \n",
       "999997  SOHODZI12A8C137BB3  TRYYYMG128F4260ECA           NaN   \n",
       "999998  SOLXGOR12A81C21EB7  TRYYYDJ128F9310A21           NaN   \n",
       "999999  SOWXJXQ12AB0189F43  TRYYYVU12903CD01E3      0.487950   \n",
       "\n",
       "        artist_familiarity  7digital_id                                title  \\\n",
       "0                 0.649822      7032331                         Silent Night   \n",
       "1                 0.439604      1514808                          Tanssi vaan   \n",
       "2                 0.643681      6945353                    No One Could Ever   \n",
       "3                 0.448501      2168257                        Si Vos Querés   \n",
       "4                 0.000000      2264873                     Tangle Of Aspens   \n",
       "...                    ...          ...                                  ...   \n",
       "999995            0.528617      7522478                      O Samba Da Vida   \n",
       "999996            0.401500      1632096                         Jago Chhadeo   \n",
       "999997            0.556918      2219291                              Novemba   \n",
       "999998            0.403668      5472456                              Faraday   \n",
       "999999            0.552977      8486723  Fernweh feat. Sektion Kuchikäschtli   \n",
       "\n",
       "                  artist  mode    tempo  key           artist_id  \n",
       "0       Faster Pussy cat     0   87.002   10  ARYZTJS1187B98C555  \n",
       "1       Karkkiautomaatti     1  150.778    9  ARMVN3U1187FB3A1EB  \n",
       "2         Hudson Mohawke     1  177.768    7  ARGEKB01187FB50750  \n",
       "3            Yerba Brava     1   87.433    7  ARNWYLR1187B9B2F9C  \n",
       "4             Der Mystic     0  140.035    5  AREQDTE1269FB37231  \n",
       "...                  ...   ...      ...  ...                 ...  \n",
       "999995      Kiko Navarro     0   92.159    7  AR7Z4J81187FB3FC59  \n",
       "999996     Kuldeep Manak     1  156.132    5  ART5FZD1187B9A7FCF  \n",
       "999997    Gabriel Le Mar     0  137.089   11  ARZ3R6M1187B9AF750  \n",
       "999998             Elude     0  137.928    6  ARCMCOK1187B9B1073  \n",
       "999999             Texta     1  164.037    6  AR7PLM21187B990D08  \n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterate through the bytestring columns to decode\n",
    "for clm in ['song_id','track_id','title','artist']:\n",
    "    print(\"Transforming: {}\".format(clm))\n",
    "    flat_summary[clm] = flat_summary[clm].str.decode(\"utf-8\")\n",
    "\n",
    "#the artist_id field is super pesky, so we had to do this one separate for some reason\n",
    "flat_summary['temp'] = flat_summary['artist_id'].str.decode(\"utf-8\") \n",
    "flat_summary.drop('artist_id', axis = 1, inplace = True)\n",
    "flat_summary.rename(columns = {'temp':'artist_id'}, inplace = True)\n",
    "flat_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>spotify_uri_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOVFVAK12A8C1350D9</td>\n",
       "      <td>spotify:track:6DOmOjeTc3btomrfFfPgy8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOGTUKN12AB017F4F1</td>\n",
       "      <td>spotify:track:41RpZW2lxAdnqDd2nMBzLQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOBNYVR12A8C13558C</td>\n",
       "      <td>spotify:track:7z4BZV7eZO1bqVKwAeTmou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOHSBXH12A8C13B0DF</td>\n",
       "      <td>spotify:track:2poHURuOfVNbzZdivAwtOH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              song_id                     spotify_uri_final\n",
       "0  SOQMMHC12AB0180CB8                                      \n",
       "1  SOVFVAK12A8C1350D9  spotify:track:6DOmOjeTc3btomrfFfPgy8\n",
       "2  SOGTUKN12AB017F4F1  spotify:track:41RpZW2lxAdnqDd2nMBzLQ\n",
       "3  SOBNYVR12A8C13558C  spotify:track:7z4BZV7eZO1bqVKwAeTmou\n",
       "4  SOHSBXH12A8C13B0DF  spotify:track:2poHURuOfVNbzZdivAwtOH"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieving the stored musicbrainz-to-spotify crosswalk\n",
    "##this was created in a different notebook\n",
    "bucket='sagemaker-msdsubset'\n",
    "data_key = 'musicbrainz_spotify_id_crosswalk.csv'\n",
    "ACCESS_KEY = 'ENTER YOUR ACCESS KEY HERE'\n",
    "SECRET_KEY = 'ENTER YOUR SECRET KEY HERE'\n",
    "s3 = S3FileSystem(key=ACCESS_KEY, secret=SECRET_KEY)\n",
    "with s3.open('sagemaker-msdsubset/songid_spotifyuri_crosswalk.csv') as xwalk:\n",
    "    spotify_xwalk = pd.read_csv(xwalk)\n",
    "    \n",
    "#they were created such that a non-match was called \"no_match\"\n",
    "##let's just turn that into the empty string\n",
    "spotify_xwalk = spotify_xwalk.loc[:,['song_id','spotify_uri_final']]\n",
    "spotify_xwalk['spotify_uri_final'] = np.where(spotify_xwalk['spotify_uri_final'] == 'no_match',\"\"\n",
    "                                              ,spotify_xwalk['spotify_uri_final'])\n",
    "spotify_xwalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7872: expected 7 fields, saw 8\\nSkipping line 11730: expected 7 fields, saw 9\\nSkipping line 14131: expected 7 fields, saw 8\\nSkipping line 58054: expected 7 fields, saw 8\\nSkipping line 58754: expected 7 fields, saw 8\\n'\n",
      "b'Skipping line 847129: expected 7 fields, saw 8\\n'\n",
      "b'Skipping line 1091153: expected 7 fields, saw 8\\nSkipping line 1175375: expected 7 fields, saw 8\\n'\n",
      "b'Skipping line 1225935: expected 7 fields, saw 8\\nSkipping line 1255357: expected 7 fields, saw 8\\nSkipping line 1279671: expected 7 fields, saw 8\\n'\n",
      "b'Skipping line 1330675: expected 7 fields, saw 8\\n'\n",
      "b'Skipping line 1448033: expected 7 fields, saw 8\\nSkipping line 1543893: expected 7 fields, saw 8\\n'\n",
      "b'Skipping line 1579569: expected 7 fields, saw 8\\nSkipping line 1612448: expected 7 fields, saw 8\\n'\n",
      "b'Skipping line 1784588: expected 7 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "#we found some more Spotify URIs laying around here: https://archive.org/details/thisismyjam-datadump\n",
    "\n",
    "#mapping:\n",
    "##wget http://millionsongdataset.com/sites/default/files/thisismyjam/jam_to_msd.tsv\n",
    "jam_walk = pd.read_csv(r'./myjam/jam_to_msd.tsv', \"\\t\", names = ['jam_id', 'track_id'])\n",
    "\n",
    "#uris (you'd have to also unzip):\n",
    "##wget https://archive.org/download/thisismyjam-datadump/thisismyjam-datadump.zip\n",
    "jam = pd.read_csv(r\"./myjam/archive/jams.tsv\", \"\\t\", error_bad_lines = False)\n",
    "\n",
    "#get rid of null uris\n",
    "jam = jam[~jam['spotify_uri'].isnull()]\n",
    "\n",
    "#slap on the MSD ID\n",
    "jam = pd.merge(jam,jam_walk,on = 'jam_id')\n",
    "jam.drop_duplicates(\"track_id\", inplace = True)\n",
    "jam = jam.loc[:,['track_id','spotify_uri']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the artist temrs from above\n",
    "flat_summary = pd.merge(flat_summary, terms, on = 'artist_id', how = 'left')\n",
    "#add the scraped URIs\n",
    "flat_summary = pd.merge(flat_summary, spotify_xwalk, on = 'song_id', how = 'left')\n",
    "#add the jams URIs\n",
    "flat_summary = pd.merge(flat_summary, jam, on = 'track_id', how = 'left')\n",
    "#make URI the missing string if its null\n",
    "flat_summary['spotify_uri_final'] = np.where(flat_summary['spotify_uri_final'] == '',\n",
    "                                            flat_summary['spotify_uri'],\n",
    "                                            flat_summary['spotify_uri_final'])\n",
    "#get rid of the interim field\n",
    "del flat_summary['spotify_uri']\n",
    "flat_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and upload to S3\n",
    "flat_summary.to_csv(r'./flat_summary.csv', index = False, header = False)\n",
    "ACCESS_KEY = 'ENTER YOUR ACCESS KEY HERE'\n",
    "SECRET_KEY = 'ENTER YOUR SECRET KEY HERE'\n",
    "s3 = boto3.Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY).resource('s3')\n",
    "bucket = s3.Bucket('sagemaker-msdsubset')\n",
    "bucket.upload_file(r'./flat_summary.csv', Key = 'flat_summary_04_09_20.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
